we wouldn't be able to have 40 or 50 models served in our platform if open-source AI models weren't hugely available, because we probably cannot train 50 models from scratch effectively. But the open source model for AI is winning, and huggingface -the main repository for open-source models- has over 1 million AI models and its growing fast. So what we are doing is selecting the best models for our region, and using our region's data to adapt them to our needs (either by parameter tuning or prompt tuning).

also we wouldn't be able to compete on model inference (both throughput and cost) if the ai models' serving engine's weren't open source. Now every company uses open source serving engines like vLLM (https://github.com/vllm-project/vllm), which have funding from big companies like nvidia, amd, aws, google, and intel; and from big VC funds like a16z, sequoia captial, and ZhenFund.
